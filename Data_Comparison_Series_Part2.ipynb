{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8430f21a",
   "metadata": {},
   "source": [
    "### Reading data from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8aac77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read\\\n",
    "          .option(\"header\",True)\\\n",
    "          .option(\"inferSchema\",True)\\\n",
    "          .csv(\"/Users/ahmed.uzzaman/Downloads/Stores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "088c594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Store_ID : integer (nullable = true)\n",
      " |-- Store_Area: integer (nullable = true)\n",
      " |-- Items_Available: integer (nullable = true)\n",
      " |-- Daily_Customer_Count: integer (nullable = true)\n",
      " |-- Store_Sales: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68c0b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read\\\n",
    "          .option(\"header\",True)\\\n",
    "          .option(\"inferSchema\",True)\\\n",
    "          .csv(\"/Users/ahmed.uzzaman/Downloads/Stores_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cff5ff43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Store_ID ,IntegerType,true),StructField(Store_Area,IntegerType,true),StructField(Items_Available,IntegerType,true),StructField(Daily_Customer_Count,IntegerType,true),StructField(Store_Sales,IntegerType,true)))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fa3eb5",
   "metadata": {},
   "source": [
    "### Finding record counts and its difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b9fa424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base count: 896\n",
      "compare count: 899\n",
      "# Difference: 3\n",
      "% Difference: 0.33482142857142855\n"
     ]
    }
   ],
   "source": [
    "df1_count = df1.count()\n",
    "df2_count = df2.count()\n",
    "\n",
    "print(\"base count:\",df1_count)\n",
    "print(\"compare count:\",df2_count)\n",
    "print(\"# Difference:\",df2_count - df1_count)\n",
    "print(\"% Difference:\",((df2_count - df1_count)/df1_count) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b70bb",
   "metadata": {},
   "source": [
    "### Finding KPI for \"Store_Sales\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7a32546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df1_kpi = df1.agg(lit(\"df1\").alias(\"Source\")\n",
    "                  ,lit(\"Store_Sales\").alias(\"Column_Name\")\n",
    "                  ,sum(\"Store_Sales\").alias(\"SUM\")\n",
    "                  ,min(\"Store_Sales\").alias(\"MIN\")\n",
    "                  ,max(\"Store_Sales\").alias(\"MAX\")\n",
    "                  ,avg(\"Store_Sales\").alias(\"AVG\"))\n",
    "df2_kpi = df2.agg(lit(\"df2\").alias(\"Source\")\n",
    "                  ,lit(\"Store_Sales\").alias(\"Column_Name\")\n",
    "                  ,sum(\"Store_Sales\").alias(\"SUM\")\n",
    "                  ,min(\"Store_Sales\").alias(\"MIN\")\n",
    "                  ,max(\"Store_Sales\").alias(\"MAX\")\n",
    "                  ,avg(\"Store_Sales\").alias(\"AVG\"))\n",
    "\n",
    "## Using JOIN clause\n",
    "merge_kpi = df1_kpi.join(df2_kpi,\"Column_Name\",\"FULL\")\n",
    "merge_kpi.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81a62411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------+-----+------+------------------+\n",
      "|Source|Column_Name|     SUM|  MIN|   MAX|               AVG|\n",
      "+------+-----------+--------+-----+------+------------------+\n",
      "|   df1|Store_Sales|53178770|14920|116320| 59351.30580357143|\n",
      "|   df2|Store_Sales|53317781|14920|116320|59307.876529477195|\n",
      "+------+-----------+--------+-----+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Using UNION clause\n",
    "merge = df1_kpi.union(df2_kpi)\n",
    "merge.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a572143",
   "metadata": {},
   "source": [
    "### Finding distinct values for \"Store_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e87ff87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+\n",
      "|Column_Name|df1_Count|df2_Count|\n",
      "+-----------+---------+---------+\n",
      "|   Store_ID|      896|      899|\n",
      "+-----------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "distinct_df1 = df1.select(lit(\"Store_ID\").alias(\"Column_Name\"),countDistinct(\"Store_ID\").alias(\"df1_Count\"))\n",
    "distinct_df2 = df2.select(lit(\"Store_ID\").alias(\"Column_Name\"),countDistinct(\"Store_ID\").alias(\"df2_Count\"))\n",
    "\n",
    "merge_distinct = distinct_df1.join(distinct_df2,\"Column_Name\",\"FULL\")\n",
    "merge_distinct.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d062114",
   "metadata": {},
   "source": [
    "### Finding missing values in df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91fe6909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------------+--------------------+-----------+\n",
      "|Store_ID|Store_Area|Items_Available|Daily_Customer_Count|Store_Sales|\n",
      "+--------+----------+---------------+--------------------+-----------+\n",
      "+--------+----------+---------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_in_df1 = df1.join(df2,\"Store_ID\",\"LEFTANTI\")\n",
    "missing_in_df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add9624",
   "metadata": {},
   "source": [
    "### Finding missing values in df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "680d6c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------------+--------------------+-----------+\n",
      "|Store_ID|Store_Area|Items_Available|Daily_Customer_Count|Store_Sales|\n",
      "+--------+----------+---------------+--------------------+-----------+\n",
      "|     897|      2151|           1555|                 566|      65214|\n",
      "|     898|      2163|           2111|                 497|      32541|\n",
      "|     899|      2174|           1002|                1021|      41256|\n",
      "+--------+----------+---------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_in_df2 = df2.join(df1,\"Store_ID\",\"LEFTANTI\")\n",
    "missing_in_df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f348c0",
   "metadata": {},
   "source": [
    "### Creating a temporary view on dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c06199cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView(\"df1_data\")\n",
    "df2.createOrReplaceTempView(\"df2_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80fbba4",
   "metadata": {},
   "source": [
    "### Finding mismatched records for Store_Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "70c2ec71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+--------------+\n",
      "|Store_ID|df1_Store_Area|df2_Store_Area|\n",
      "+--------+--------------+--------------+\n",
      "|      92|          2169|          2099|\n",
      "|     399|          2063|          2074|\n",
      "|     467|          2229|          2118|\n",
      "|     541|          2214|          2105|\n",
      "|     850|          2067|          2079|\n",
      "+--------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = f\"\"\"\n",
    "        SELECT c.Store_ID\n",
    "               ,c.Store_Area AS df1_Store_Area\n",
    "               ,f.Store_Area AS df2_Store_Area\n",
    "        FROM   df1_data c\n",
    "               JOIN df2_data f\n",
    "                 ON c.Store_ID = f.Store_ID\n",
    "        WHERE  c.Store_Area != f.Store_Area\"\"\"\n",
    "df_mismatch = spark.sql(q)\n",
    "df_mismatch.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9df7ff",
   "metadata": {},
   "source": [
    "### Finding mismatches in df1 using exceptAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30d97ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------------+--------------------+-----------+\n",
      "|Store_ID|Store_Area|Items_Available|Daily_Customer_Count|Store_Sales|\n",
      "+--------+----------+---------------+--------------------+-----------+\n",
      "|     399|      2063|           2493|                 810|      51480|\n",
      "|      92|      2169|           2617|                 600|      67080|\n",
      "|     467|      2229|           2667|                 660|      87410|\n",
      "|     541|      2214|           2647|                 740|      65900|\n",
      "|     850|      2067|           2492|                 790|      70230|\n",
      "+--------+----------+---------------+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 116:>                                                        (0 + 2) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.exceptAll(df2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5bc127",
   "metadata": {},
   "source": [
    "### Finding mismatches in df2 using exceptAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9ab73a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------------+--------------------+-----------+\n",
      "|Store_ID|Store_Area|Items_Available|Daily_Customer_Count|Store_Sales|\n",
      "+--------+----------+---------------+--------------------+-----------+\n",
      "|     399|      2074|           2493|                 810|      51480|\n",
      "|     850|      2079|           2492|                 790|      70230|\n",
      "|      92|      2099|           2617|                 600|      67080|\n",
      "|     897|      2151|           1555|                 566|      65214|\n",
      "|     467|      2118|           2667|                 660|      87410|\n",
      "|     898|      2163|           2111|                 497|      32541|\n",
      "|     899|      2174|           1002|                1021|      41256|\n",
      "|     541|      2105|           2647|                 740|      65900|\n",
      "+--------+----------+---------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.exceptAll(df1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c2be63",
   "metadata": {},
   "source": [
    "### Finding duplicate values in df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb993c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Store_ID|count|\n",
      "+--------+-----+\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_duplicate = df1.groupBy(\"Store_ID\").count().filter(\"count > 1\")\n",
    "df1_duplicate.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8987fd7d",
   "metadata": {},
   "source": [
    "### Finding duplicate values in df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4413cb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Store_ID|count|\n",
      "+--------+-----+\n",
      "|     899|    2|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_duplicate = df2.groupBy(\"Store_ID\").count().filter(\"count > 1\")\n",
    "df2_duplicate.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd3cfc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
